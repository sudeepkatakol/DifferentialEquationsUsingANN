{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters_deep(layer_dims): \n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "\n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l - 1]) \\\n",
    "        * np.sqrt(2.0 / layer_dims[l - 1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "        \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l - 1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1 + np.exp(-Z)), Z\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z), Z\n",
    "\n",
    "def tanh(Z):\n",
    "    return np.tanh(Z), Z\n",
    "\n",
    "def cos(Z):\n",
    "    return np.cos(Z), Z\n",
    "\n",
    "def softmax(Z):\n",
    "    shift = Z - np.maximum(Z)\n",
    "    exps = np.exp(shift)\n",
    "    return exps / np.sum(exps), Z\n",
    "\n",
    "def softplus(Z):\n",
    "    return np.log(np.exp(Z) + 1), Z\n",
    "\n",
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W, A) + b\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation, dA_prev):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        dA = np.multiply(A, 1 - A) * np.dot(W, dA_prev)  \n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        dA = np.greater_equal(Z, 0) * np.dot(W, dA_prev)\n",
    "    \n",
    "    elif activation == \"none\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = Z, Z\n",
    "        dA = np.dot(W, dA_prev)\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = tanh(Z)\n",
    "        dA = (np.ones_like(A) - A**2) * np.dot(W, dA_prev)\n",
    "        \n",
    "    elif activation == \"cos\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = cos(Z)\n",
    "        dA = - np.sin(Z) * np.dot(W, dA_prev)\n",
    "    \n",
    "    elif activation == \"softplus\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softplus(Z)\n",
    "        dA =  sigmoid(Z)[0] * np.dot(W, dA_prev)\n",
    "        \n",
    "    elif activation == \"softmax\":\n",
    "        pass\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    assert (dA.shape == A.shape)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache, dA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters, activation):\n",
    "    caches = []\n",
    "    A = X\n",
    "    dA = np.ones_like(A)\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        dA_prev = dA\n",
    "        A, cache, dA = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation, dA_prev)\n",
    "        caches.append(cache)\n",
    "\n",
    "    AL, cache, dAL = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], \"none\", dA)\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (parameters['W' + str(L)].shape[0], X.shape[1]))\n",
    "    assert(dAL.shape == AL.shape)        \n",
    "    return AL, caches, dAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, activation_cache):\n",
    "    y = sigmoid(activation_cache)[0]\n",
    "    return np.multiply(dA, np.multiply(y, 1 - y))\n",
    "\n",
    "def relu_backward(dA, activation_cache):\n",
    "    y = np.greater_equal(activation_cache, 0)\n",
    "    return np.multiply(dA, y)\n",
    "\n",
    "def none_backward(dA, activation_cache):\n",
    "    return dA\n",
    "\n",
    "def cos_backward(dA, activation_cache):\n",
    "    return np.multiply(dA, -np.sin(activation_cache))\n",
    "\n",
    "def tanh_backward(dA, activation_cache):\n",
    "    return np.multiply(dA, np.ones_like(dA) - np.tanh(activation_cache)**2)\n",
    "\n",
    "def softplus_backward(dA, activation_cache):\n",
    "    return np.multiply(dA, sigmoid(activation_cache)[0])\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = np.dot(dZ, cache[0].T) / m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True) / m\n",
    "    dA_prev = np.dot(cache[1].T, dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "    \n",
    "    elif activation == \"none\":\n",
    "        dZ = none_backward(dA, activation_cache)\n",
    "    \n",
    "    elif activation == \"tanh\":\n",
    "        dZ = tanh_backward(dA, activation_cache)\n",
    "        \n",
    "    elif activation == \"cos\":\n",
    "        dZ = cos_backward(dA, activation_cache)\n",
    "    \n",
    "    elif activation == \"softplus\":\n",
    "        dZ = softplus_backward(dA, activation_cache)\n",
    "    \n",
    "    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_model_backward(AL, dAL, caches, activation):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    m = AL.shape[1]\n",
    "    \n",
    "    current_cache = caches[-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = \"none\")\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation)\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_adam(parameters) :   \n",
    "    L = len(parameters) // 2 \n",
    "    v = {}\n",
    "    s = {}\n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        v[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "\n",
    "        s[\"dW\" + str(l + 1)] = np.zeros_like(parameters[\"W\" + str(l + 1)])\n",
    "        s[\"db\" + str(l + 1)] = np.zeros_like(parameters[\"b\" + str(l + 1)])\n",
    "    return v, s\n",
    "\n",
    "def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate=0.01,\n",
    "                                beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "    \n",
    "    L = len(parameters) // 2                 # number of layers in the neural networks\n",
    "    v_corrected = {}                         # Initializing first moment estimate, python dictionary\n",
    "    s_corrected = {}                         # Initializing second moment estimate, python dictionary\n",
    "    \n",
    "    \n",
    "    for l in range(L):\n",
    "        v[\"dW\" + str(l + 1)] = beta1 * v[\"dW\" + str(l + 1)] + (1 - beta1) * grads['dW' + str(l + 1)]\n",
    "        v[\"db\" + str(l + 1)] = beta1 * v[\"db\" + str(l + 1)] + (1 - beta1) * grads['db' + str(l + 1)]\n",
    "        \n",
    "        v_corrected[\"dW\" + str(l + 1)] = v[\"dW\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "        v_corrected[\"db\" + str(l + 1)] = v[\"db\" + str(l + 1)] / (1 - np.power(beta1, t))\n",
    "       \n",
    "        s[\"dW\" + str(l + 1)] = beta2 * s[\"dW\" + str(l + 1)] + (1 - beta2) * np.power(grads['dW' + str(l + 1)], 2)\n",
    "        s[\"db\" + str(l + 1)] = beta2 * s[\"db\" + str(l + 1)] + (1 - beta2) * np.power(grads['db' + str(l + 1)], 2)\n",
    "        \n",
    "        s_corrected[\"dW\" + str(l + 1)] = s[\"dW\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "        s_corrected[\"db\" + str(l + 1)] = s[\"db\" + str(l + 1)] / (1 - np.power(beta2, t))\n",
    "       \n",
    "        parameters[\"W\" + str(l + 1)] = parameters[\"W\" + str(l + 1)] - learning_rate * v_corrected[\"dW\" + str(l + 1)] / np.sqrt(s[\"dW\" + str(l + 1)] + epsilon)\n",
    "        parameters[\"b\" + str(l + 1)] = parameters[\"b\" + str(l + 1)] - learning_rate * v_corrected[\"db\" + str(l + 1)] / np.sqrt(s[\"db\" + str(l + 1)] + epsilon)\n",
    "      \n",
    "    return parameters, v, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autograd import grad\n",
    "\n",
    "def solve():\n",
    "    def dX_dt(T, X):\n",
    "        retu = np.array([X[0] + X[1] + T, X[3] + X[1] + (1 + T**2), X[3] + X[1] + (1 + T**2), 4/9*(X[0] + X[1] + T)]).reshape(4, T.shape[1])\n",
    "        return retu\n",
    "        \n",
    "    def predicted_soln(T, AL):\n",
    "        sol = np.multiply(T, AL) + np.array([1, 0, 0, 1]).reshape((4, 1))\n",
    "        assert(sol.shape == AL.shape)\n",
    "        return sol\n",
    "    \n",
    "    def grad_predicted_soln(T, AL, dAL):\n",
    "        return AL + T*dAL\n",
    "    \n",
    "    def cost(AL, dAL, T):\n",
    "        X = predicted_soln(T, AL)\n",
    "        term1 = dX_dt(T, X)\n",
    "        term2 = AL + T*dAL\n",
    "        cost = np.sum((term1 - term2)**2, axis = 0, keepdims = True)\n",
    "        #print(cost.shape)\n",
    "        assert(cost.shape == (1, batch_size))\n",
    "        cost = np.squeeze(np.mean(cost))\n",
    "        return cost\n",
    "    \n",
    "    def compute_cost(AL, dAL, T):\n",
    "        return cost(AL, dAL, T), grad(cost)(AL, dAL, T)\n",
    "    \n",
    "    batch_size = 1000\n",
    "    \n",
    "    def get_data():\n",
    "        #h = np.random.uniform(0,5,batch_size)\n",
    "        h = np.arange(0, 5, 5/batch_size)\n",
    "        h.shape = (1, batch_size)\n",
    "        return h\n",
    "    \n",
    "    return get_data, predicted_soln, grad_predicted_soln, compute_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 176.467866\n",
      "Cost after iteration 100: 14.944429\n",
      "Cost after iteration 200: 14.501755\n",
      "Cost after iteration 300: 14.348732\n",
      "Cost after iteration 400: 14.235524\n",
      "Cost after iteration 500: 13.566394\n"
     ]
    }
   ],
   "source": [
    "get_data, predicted, grad_predicted, compute_cost = solve()\n",
    "\n",
    "layers_dims = [1, 4, 4, 4, 4]\n",
    "\n",
    "L = len(layers_dims)             # number of layers in the neural networks\n",
    "costs = []                       # to keep track of the cost\n",
    "t = 0                            # initializing the counter required for Adam update\n",
    "seed = 10                        # For grading purposes, so that your \"random\" minibatches are the same as ours\n",
    "\n",
    "num_epochs = 501\n",
    "\n",
    "parameters = initialize_parameters_deep(layers_dims)\n",
    "v, s = initialize_adam(parameters)\n",
    "\n",
    "activation = 'sigmoid'\n",
    "\n",
    "print_cost = True\n",
    "\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    X = get_data()\n",
    "    \n",
    "    AL, caches, dAL = L_model_forward(X, parameters, activation)\n",
    "    \n",
    "    cost, dAL = compute_cost(AL, dAL, X)\n",
    "   \n",
    "    grads = L_model_backward(AL, dAL, caches, activation)\n",
    "    \n",
    "    '''\n",
    "    # Perform check\n",
    "    Y = dx_dt(AL)\n",
    "    gradient_checker(parameters, grads, Y, X)\n",
    "    break\n",
    "    '''\n",
    "    \n",
    "    t = t + 1\n",
    "    parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t)\n",
    "    \n",
    "    if print_cost and i % 100 == 0:\n",
    "        print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    if print_cost and i % 100 == 0:\n",
    "        costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 13.553467\n",
      "Cost after iteration 100: 16.427231\n",
      "Cost after iteration 200: 16.376594\n",
      "Cost after iteration 300: 16.628907\n",
      "Cost after iteration 400: 16.677299\n",
      "Cost after iteration 500: 16.514438\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 501\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    X = get_data()\n",
    "    \n",
    "    AL, caches, dAL = L_model_forward(X, parameters, activation)\n",
    "    \n",
    "    cost, dAL = compute_cost(AL, dAL, X)\n",
    "   \n",
    "    grads = L_model_backward(AL, dAL, caches, activation)\n",
    "    \n",
    "    '''\n",
    "    # Perform check\n",
    "    Y = dx_dt(AL)\n",
    "    gradient_checker(parameters, grads, Y, X)\n",
    "    break\n",
    "    '''\n",
    "    \n",
    "    t = t + 1\n",
    "    parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t)\n",
    "    \n",
    "    if print_cost and i % 100 == 0:\n",
    "        print (\"Cost after iteration %i: %f\" % (i, cost))\n",
    "    if print_cost and i % 100 == 0:\n",
    "        costs.append(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   9.96147385e-01,   9.92287698e-01,\n",
       "         9.88420786e-01,   9.84546490e-01,   9.80664649e-01,\n",
       "         9.76775101e-01,   9.72877679e-01,   9.68972212e-01,\n",
       "         9.65058528e-01,   9.61136450e-01,   9.57205799e-01,\n",
       "         9.53266392e-01,   9.49318043e-01,   9.45360562e-01,\n",
       "         9.41393756e-01,   9.37417428e-01,   9.33431378e-01,\n",
       "         9.29435403e-01,   9.25429295e-01,   9.21412844e-01,\n",
       "         9.17385834e-01,   9.13348047e-01,   9.09299262e-01,\n",
       "         9.05239251e-01,   9.01167787e-01,   8.97084634e-01,\n",
       "         8.92989555e-01,   8.88882309e-01,   8.84762650e-01,\n",
       "         8.80630329e-01,   8.76485093e-01,   8.72326683e-01,\n",
       "         8.68154839e-01,   8.63969295e-01,   8.59769781e-01,\n",
       "         8.55556023e-01,   8.51327744e-01,   8.47084660e-01,\n",
       "         8.42826486e-01,   8.38552932e-01,   8.34263702e-01,\n",
       "         8.29958498e-01,   8.25637017e-01,   8.21298953e-01,\n",
       "         8.16943992e-01,   8.12571821e-01,   8.08182120e-01,\n",
       "         8.03774564e-01,   7.99348827e-01,   7.94904576e-01,\n",
       "         7.90441476e-01,   7.85959187e-01,   7.81457365e-01,\n",
       "         7.76935663e-01,   7.72393728e-01,   7.67831206e-01,\n",
       "         7.63247737e-01,   7.58642959e-01,   7.54016505e-01,\n",
       "         7.49368005e-01,   7.44697086e-01,   7.40003371e-01,\n",
       "         7.35286480e-01,   7.30546029e-01,   7.25781632e-01,\n",
       "         7.20992900e-01,   7.16179439e-01,   7.11340856e-01,\n",
       "         7.06476753e-01,   7.01586728e-01,   6.96670380e-01,\n",
       "         6.91727303e-01,   6.86757091e-01,   6.81759335e-01,\n",
       "         6.76733624e-01,   6.71679546e-01,   6.66596687e-01,\n",
       "         6.61484632e-01,   6.56342967e-01,   6.51171272e-01,\n",
       "         6.45969133e-01,   6.40736129e-01,   6.35471845e-01,\n",
       "         6.30175860e-01,   6.24847758e-01,   6.19487121e-01,\n",
       "         6.14093533e-01,   6.08666577e-01,   6.03205839e-01,\n",
       "         5.97710906e-01,   5.92181366e-01,   5.86616810e-01,\n",
       "         5.81016831e-01,   5.75381024e-01,   5.69708987e-01,\n",
       "         5.64000322e-01,   5.58254631e-01,   5.52471525e-01,\n",
       "         5.46650614e-01,   5.40791516e-01,   5.34893850e-01,\n",
       "         5.28957243e-01,   5.22981325e-01,   5.16965733e-01,\n",
       "         5.10910109e-01,   5.04814100e-01,   4.98677361e-01,\n",
       "         4.92499552e-01,   4.86280343e-01,   4.80019407e-01,\n",
       "         4.73716427e-01,   4.67371095e-01,   4.60983108e-01,\n",
       "         4.54552173e-01,   4.48078007e-01,   4.41560334e-01,\n",
       "         4.34998887e-01,   4.28393411e-01,   4.21743658e-01,\n",
       "         4.15049392e-01,   4.08310385e-01,   4.01526423e-01,\n",
       "         3.94697299e-01,   3.87822820e-01,   3.80902802e-01,\n",
       "         3.73937074e-01,   3.66925475e-01,   3.59867857e-01,\n",
       "         3.52764083e-01,   3.45614029e-01,   3.38417583e-01,\n",
       "         3.31174645e-01,   3.23885128e-01,   3.16548958e-01,\n",
       "         3.09166071e-01,   3.01736420e-01,   2.94259968e-01,\n",
       "         2.86736692e-01,   2.79166582e-01,   2.71549640e-01,\n",
       "         2.63885882e-01,   2.56175337e-01,   2.48418048e-01,\n",
       "         2.40614068e-01,   2.32763467e-01,   2.24866325e-01,\n",
       "         2.16922736e-01,   2.08932806e-01,   2.00896655e-01,\n",
       "         1.92814415e-01,   1.84686230e-01,   1.76512256e-01,\n",
       "         1.68292664e-01,   1.60027634e-01,   1.51717359e-01,\n",
       "         1.43362044e-01,   1.34961905e-01,   1.26517169e-01,\n",
       "         1.18028075e-01,   1.09494873e-01,   1.00917823e-01,\n",
       "         9.22971948e-02,   8.36332699e-02,   7.49263387e-02,\n",
       "         6.61767016e-02,   5.73846681e-02,   4.85505569e-02,\n",
       "         3.96746955e-02,   3.07574199e-02,   2.17990743e-02,\n",
       "         1.28000105e-02,   3.76058843e-03,  -5.31882523e-03,\n",
       "        -1.44378566e-02,  -2.35961252e-02,  -3.27932443e-02,\n",
       "        -4.20288211e-02,  -5.13024573e-02,  -6.06137491e-02,\n",
       "        -6.99622876e-02,  -7.93476596e-02,  -8.87694470e-02,\n",
       "        -9.82272282e-02,  -1.07720577e-01,  -1.17249066e-01,\n",
       "        -1.26812261e-01,  -1.36409729e-01,  -1.46041031e-01,\n",
       "        -1.55705729e-01,  -1.65403381e-01,  -1.75133543e-01,\n",
       "        -1.84895773e-01,  -1.94689624e-01,  -2.04514651e-01,\n",
       "        -2.14370407e-01,  -2.24256447e-01,  -2.34172322e-01,\n",
       "        -2.44117589e-01,  -2.54091801e-01,  -2.64094513e-01,\n",
       "        -2.74125283e-01,  -2.84183668e-01,  -2.94269227e-01,\n",
       "        -3.04381523e-01,  -3.14520117e-01,  -3.24684577e-01,\n",
       "        -3.34874469e-01,  -3.45089364e-01,  -3.55328836e-01,\n",
       "        -3.65592460e-01,  -3.75879816e-01,  -3.86190486e-01,\n",
       "        -3.96524056e-01,  -4.06880117e-01,  -4.17258261e-01,\n",
       "        -4.27658086e-01,  -4.38079192e-01,  -4.48521185e-01,\n",
       "        -4.58983675e-01,  -4.69466276e-01,  -4.79968605e-01,\n",
       "        -4.90490286e-01,  -5.01030946e-01,  -5.11590217e-01,\n",
       "        -5.22167736e-01,  -5.32763145e-01,  -5.43376091e-01,\n",
       "        -5.54006225e-01,  -5.64653204e-01,  -5.75316690e-01,\n",
       "        -5.85996349e-01,  -5.96691854e-01,  -6.07402883e-01,\n",
       "        -6.18129117e-01,  -6.28870244e-01,  -6.39625957e-01,\n",
       "        -6.50395955e-01,  -6.61179942e-01,  -6.71977626e-01,\n",
       "        -6.82788721e-01,  -6.93612947e-01,  -7.04450030e-01,\n",
       "        -7.15299698e-01,  -7.26161689e-01,  -7.37035742e-01,\n",
       "        -7.47921604e-01,  -7.58819026e-01,  -7.69727764e-01,\n",
       "        -7.80647582e-01,  -7.91578245e-01,  -8.02519525e-01,\n",
       "        -8.13471201e-01,  -8.24433055e-01,  -8.35404873e-01,\n",
       "        -8.46386450e-01,  -8.57377581e-01,  -8.68378071e-01,\n",
       "        -8.79387726e-01,  -8.90406359e-01,  -9.01433786e-01,\n",
       "        -9.12469830e-01,  -9.23514318e-01,  -9.34567082e-01,\n",
       "        -9.45627956e-01,  -9.56696782e-01,  -9.67773406e-01,\n",
       "        -9.78857676e-01,  -9.89949448e-01,  -1.00104858e+00,\n",
       "        -1.01215493e+00,  -1.02326838e+00,  -1.03438879e+00,\n",
       "        -1.04551603e+00,  -1.05664999e+00,  -1.06779056e+00,\n",
       "        -1.07893761e+00,  -1.09009104e+00,  -1.10125076e+00,\n",
       "        -1.11241665e+00,  -1.12358862e+00,  -1.13476658e+00,\n",
       "        -1.14595044e+00,  -1.15714011e+00,  -1.16833552e+00,\n",
       "        -1.17953658e+00,  -1.19074322e+00,  -1.20195537e+00,\n",
       "        -1.21317297e+00,  -1.22439594e+00,  -1.23562422e+00,\n",
       "        -1.24685777e+00,  -1.25809651e+00,  -1.26934041e+00,\n",
       "        -1.28058942e+00,  -1.29184348e+00,  -1.30310255e+00,\n",
       "        -1.31436660e+00,  -1.32563559e+00,  -1.33690949e+00,\n",
       "        -1.34818826e+00,  -1.35947187e+00,  -1.37076030e+00,\n",
       "        -1.38205353e+00,  -1.39335154e+00,  -1.40465430e+00,\n",
       "        -1.41596181e+00,  -1.42727404e+00,  -1.43859099e+00,\n",
       "        -1.44991265e+00,  -1.46123902e+00,  -1.47257008e+00,\n",
       "        -1.48390584e+00,  -1.49524630e+00,  -1.50659147e+00,\n",
       "        -1.51794133e+00,  -1.52929591e+00,  -1.54065521e+00,\n",
       "        -1.55201924e+00,  -1.56338802e+00,  -1.57476155e+00,\n",
       "        -1.58613986e+00,  -1.59752296e+00,  -1.60891088e+00,\n",
       "        -1.62030363e+00,  -1.63170123e+00,  -1.64310372e+00,\n",
       "        -1.65451112e+00,  -1.66592345e+00,  -1.67734075e+00,\n",
       "        -1.68876305e+00,  -1.70019037e+00,  -1.71162277e+00,\n",
       "        -1.72306025e+00,  -1.73450288e+00,  -1.74595068e+00,\n",
       "        -1.75740369e+00,  -1.76886195e+00,  -1.78032552e+00,\n",
       "        -1.79179442e+00,  -1.80326870e+00,  -1.81474841e+00,\n",
       "        -1.82623359e+00,  -1.83772430e+00,  -1.84922058e+00,\n",
       "        -1.86072247e+00,  -1.87223004e+00,  -1.88374333e+00,\n",
       "        -1.89526240e+00,  -1.90678730e+00,  -1.91831807e+00,\n",
       "        -1.92985479e+00,  -1.94139750e+00,  -1.95294626e+00,\n",
       "        -1.96450113e+00,  -1.97606216e+00,  -1.98762943e+00,\n",
       "        -1.99920297e+00,  -2.01078287e+00,  -2.02236917e+00,\n",
       "        -2.03396194e+00,  -2.04556125e+00,  -2.05716714e+00,\n",
       "        -2.06877970e+00,  -2.08039898e+00,  -2.09202505e+00,\n",
       "        -2.10365797e+00,  -2.11529780e+00,  -2.12694463e+00,\n",
       "        -2.13859850e+00,  -2.15025949e+00,  -2.16192766e+00,\n",
       "        -2.17360309e+00,  -2.18528584e+00,  -2.19697598e+00,\n",
       "        -2.20867358e+00,  -2.22037871e+00,  -2.23209143e+00,\n",
       "        -2.24381182e+00,  -2.25553995e+00,  -2.26727588e+00,\n",
       "        -2.27901970e+00,  -2.29077145e+00,  -2.30253123e+00,\n",
       "        -2.31429910e+00,  -2.32607513e+00,  -2.33785938e+00,\n",
       "        -2.34965195e+00,  -2.36145288e+00,  -2.37326226e+00,\n",
       "        -2.38508016e+00,  -2.39690665e+00,  -2.40874180e+00,\n",
       "        -2.42058568e+00,  -2.43243836e+00,  -2.44429992e+00,\n",
       "        -2.45617042e+00,  -2.46804994e+00,  -2.47993855e+00,\n",
       "        -2.49183632e+00,  -2.50374333e+00,  -2.51565963e+00,\n",
       "        -2.52758531e+00,  -2.53952044e+00,  -2.55146508e+00,\n",
       "        -2.56341931e+00,  -2.57538319e+00,  -2.58735680e+00,\n",
       "        -2.59934020e+00,  -2.61133347e+00,  -2.62333668e+00,\n",
       "        -2.63534989e+00,  -2.64737318e+00,  -2.65940661e+00,\n",
       "        -2.67145025e+00,  -2.68350417e+00,  -2.69556844e+00,\n",
       "        -2.70764312e+00,  -2.71972828e+00,  -2.73182399e+00,\n",
       "        -2.74393032e+00,  -2.75604733e+00,  -2.76817508e+00,\n",
       "        -2.78031365e+00,  -2.79246309e+00,  -2.80462347e+00,\n",
       "        -2.81679486e+00,  -2.82897732e+00,  -2.84117091e+00,\n",
       "        -2.85337570e+00,  -2.86559174e+00,  -2.87781911e+00,\n",
       "        -2.89005785e+00,  -2.90230803e+00,  -2.91456972e+00,\n",
       "        -2.92684296e+00,  -2.93912783e+00,  -2.95142437e+00,\n",
       "        -2.96373265e+00,  -2.97605273e+00,  -2.98838465e+00,\n",
       "        -3.00072849e+00,  -3.01308428e+00,  -3.02545210e+00,\n",
       "        -3.03783198e+00,  -3.05022399e+00,  -3.06262819e+00,\n",
       "        -3.07504461e+00,  -3.08747332e+00,  -3.09991436e+00,\n",
       "        -3.11236779e+00,  -3.12483365e+00,  -3.13731200e+00,\n",
       "        -3.14980288e+00,  -3.16230634e+00,  -3.17482244e+00,\n",
       "        -3.18735120e+00,  -3.19989269e+00,  -3.21244694e+00,\n",
       "        -3.22501400e+00,  -3.23759391e+00,  -3.25018671e+00,\n",
       "        -3.26279246e+00,  -3.27541118e+00,  -3.28804292e+00,\n",
       "        -3.30068771e+00,  -3.31334560e+00,  -3.32601663e+00,\n",
       "        -3.33870083e+00,  -3.35139823e+00,  -3.36410888e+00,\n",
       "        -3.37683280e+00,  -3.38957003e+00,  -3.40232061e+00,\n",
       "        -3.41508456e+00,  -3.42786192e+00,  -3.44065271e+00,\n",
       "        -3.45345698e+00,  -3.46627473e+00,  -3.47910601e+00,\n",
       "        -3.49195083e+00,  -3.50480923e+00,  -3.51768123e+00,\n",
       "        -3.53056685e+00,  -3.54346612e+00,  -3.55637906e+00,\n",
       "        -3.56930569e+00,  -3.58224602e+00,  -3.59520009e+00,\n",
       "        -3.60816790e+00,  -3.62114948e+00,  -3.63414484e+00,\n",
       "        -3.64715399e+00,  -3.66017696e+00,  -3.67321375e+00,\n",
       "        -3.68626439e+00,  -3.69932887e+00,  -3.71240721e+00,\n",
       "        -3.72549942e+00,  -3.73860550e+00,  -3.75172548e+00,\n",
       "        -3.76485935e+00,  -3.77800712e+00,  -3.79116879e+00,\n",
       "        -3.80434437e+00,  -3.81753386e+00,  -3.83073726e+00,\n",
       "        -3.84395457e+00,  -3.85718580e+00,  -3.87043094e+00,\n",
       "        -3.88368999e+00,  -3.89696295e+00,  -3.91024981e+00,\n",
       "        -3.92355056e+00,  -3.93686521e+00,  -3.95019374e+00,\n",
       "        -3.96353614e+00,  -3.97689242e+00,  -3.99026254e+00,\n",
       "        -4.00364651e+00,  -4.01704432e+00,  -4.03045594e+00,\n",
       "        -4.04388137e+00,  -4.05732058e+00,  -4.07077357e+00,\n",
       "        -4.08424032e+00,  -4.09772080e+00,  -4.11121500e+00,\n",
       "        -4.12472289e+00,  -4.13824446e+00,  -4.15177969e+00,\n",
       "        -4.16532854e+00,  -4.17889100e+00,  -4.19246704e+00,\n",
       "        -4.20605664e+00,  -4.21965975e+00,  -4.23327637e+00,\n",
       "        -4.24690646e+00,  -4.26054998e+00,  -4.27420690e+00,\n",
       "        -4.28787721e+00,  -4.30156085e+00,  -4.31525779e+00,\n",
       "        -4.32896801e+00,  -4.34269146e+00,  -4.35642811e+00,\n",
       "        -4.37017791e+00,  -4.38394084e+00,  -4.39771684e+00,\n",
       "        -4.41150588e+00,  -4.42530791e+00,  -4.43912290e+00,\n",
       "        -4.45295079e+00,  -4.46679155e+00,  -4.48064513e+00,\n",
       "        -4.49451147e+00,  -4.50839053e+00,  -4.52228227e+00,\n",
       "        -4.53618663e+00,  -4.55010357e+00,  -4.56403302e+00,\n",
       "        -4.57797495e+00,  -4.59192929e+00,  -4.60589599e+00,\n",
       "        -4.61987499e+00,  -4.63386625e+00,  -4.64786970e+00,\n",
       "        -4.66188528e+00,  -4.67591294e+00,  -4.68995262e+00,\n",
       "        -4.70400426e+00,  -4.71806779e+00,  -4.73214315e+00,\n",
       "        -4.74623029e+00,  -4.76032913e+00,  -4.77443962e+00,\n",
       "        -4.78856168e+00,  -4.80269525e+00,  -4.81684027e+00,\n",
       "        -4.83099667e+00,  -4.84516437e+00,  -4.85934331e+00,\n",
       "        -4.87353342e+00,  -4.88773463e+00,  -4.90194687e+00,\n",
       "        -4.91617006e+00,  -4.93040413e+00,  -4.94464901e+00,\n",
       "        -4.95890462e+00,  -4.97317089e+00,  -4.98744775e+00,\n",
       "        -5.00173511e+00,  -5.01603289e+00,  -5.03034103e+00,\n",
       "        -5.04465944e+00,  -5.05898804e+00,  -5.07332676e+00,\n",
       "        -5.08767551e+00,  -5.10203421e+00,  -5.11640278e+00,\n",
       "        -5.13078114e+00,  -5.14516920e+00,  -5.15956689e+00,\n",
       "        -5.17397411e+00,  -5.18839078e+00,  -5.20281682e+00,\n",
       "        -5.21725214e+00,  -5.23169666e+00,  -5.24615029e+00,\n",
       "        -5.26061293e+00,  -5.27508451e+00,  -5.28956494e+00,\n",
       "        -5.30405412e+00,  -5.31855196e+00,  -5.33305839e+00,\n",
       "        -5.34757329e+00,  -5.36209660e+00,  -5.37662821e+00,\n",
       "        -5.39116803e+00,  -5.40571598e+00,  -5.42027195e+00,\n",
       "        -5.43483586e+00,  -5.44940761e+00,  -5.46398711e+00,\n",
       "        -5.47857426e+00,  -5.49316898e+00,  -5.50777116e+00,\n",
       "        -5.52238071e+00,  -5.53699754e+00,  -5.55162155e+00,\n",
       "        -5.56625264e+00,  -5.58089072e+00,  -5.59553570e+00,\n",
       "        -5.61018747e+00,  -5.62484593e+00,  -5.63951100e+00,\n",
       "        -5.65418257e+00,  -5.66886055e+00,  -5.68354484e+00,\n",
       "        -5.69823533e+00,  -5.71293194e+00,  -5.72763456e+00,\n",
       "        -5.74234309e+00,  -5.75705744e+00,  -5.77177750e+00,\n",
       "        -5.78650319e+00,  -5.80123439e+00,  -5.81597101e+00,\n",
       "        -5.83071295e+00,  -5.84546011e+00,  -5.86021239e+00,\n",
       "        -5.87496969e+00,  -5.88973192e+00,  -5.90449896e+00,\n",
       "        -5.91927073e+00,  -5.93404711e+00,  -5.94882802e+00,\n",
       "        -5.96361335e+00,  -5.97840300e+00,  -5.99319688e+00,\n",
       "        -6.00799487e+00,  -6.02279689e+00,  -6.03760283e+00,\n",
       "        -6.05241260e+00,  -6.06722608e+00,  -6.08204319e+00,\n",
       "        -6.09686383e+00,  -6.11168789e+00,  -6.12651527e+00,\n",
       "        -6.14134588e+00,  -6.15617962e+00,  -6.17101639e+00,\n",
       "        -6.18585608e+00,  -6.20069861e+00,  -6.21554387e+00,\n",
       "        -6.23039176e+00,  -6.24524219e+00,  -6.26009506e+00,\n",
       "        -6.27495026e+00,  -6.28980771e+00,  -6.30466731e+00,\n",
       "        -6.31952895e+00,  -6.33439255e+00,  -6.34925800e+00,\n",
       "        -6.36412521e+00,  -6.37899408e+00,  -6.39386452e+00,\n",
       "        -6.40873644e+00,  -6.42360972e+00,  -6.43848430e+00,\n",
       "        -6.45336005e+00,  -6.46823690e+00,  -6.48311475e+00,\n",
       "        -6.49799351e+00,  -6.51287308e+00,  -6.52775336e+00,\n",
       "        -6.54263428e+00,  -6.55751573e+00,  -6.57239762e+00,\n",
       "        -6.58727986e+00,  -6.60216237e+00,  -6.61704504e+00,\n",
       "        -6.63192780e+00,  -6.64681054e+00,  -6.66169319e+00,\n",
       "        -6.67657564e+00,  -6.69145783e+00,  -6.70633964e+00,\n",
       "        -6.72122101e+00,  -6.73610183e+00,  -6.75098203e+00,\n",
       "        -6.76586152e+00,  -6.78074021e+00,  -6.79561801e+00,\n",
       "        -6.81049485e+00,  -6.82537064e+00,  -6.84024529e+00,\n",
       "        -6.85511872e+00,  -6.86999085e+00,  -6.88486160e+00,\n",
       "        -6.89973088e+00,  -6.91459861e+00,  -6.92946471e+00,\n",
       "        -6.94432911e+00,  -6.95919172e+00,  -6.97405247e+00,\n",
       "        -6.98891127e+00,  -7.00376805e+00,  -7.01862272e+00,\n",
       "        -7.03347522e+00,  -7.04832547e+00,  -7.06317339e+00,\n",
       "        -7.07801891e+00,  -7.09286195e+00,  -7.10770243e+00,\n",
       "        -7.12254030e+00,  -7.13737546e+00,  -7.15220785e+00,\n",
       "        -7.16703741e+00,  -7.18186405e+00,  -7.19668770e+00,\n",
       "        -7.21150831e+00,  -7.22632579e+00,  -7.24114009e+00,\n",
       "        -7.25595112e+00,  -7.27075884e+00,  -7.28556316e+00,\n",
       "        -7.30036402e+00,  -7.31516136e+00,  -7.32995512e+00,\n",
       "        -7.34474522e+00,  -7.35953161e+00,  -7.37431422e+00,\n",
       "        -7.38909299e+00,  -7.40386786e+00,  -7.41863876e+00,\n",
       "        -7.43340565e+00,  -7.44816845e+00,  -7.46292711e+00,\n",
       "        -7.47768158e+00,  -7.49243178e+00,  -7.50717768e+00,\n",
       "        -7.52191920e+00,  -7.53665629e+00,  -7.55138891e+00,\n",
       "        -7.56611699e+00,  -7.58084048e+00,  -7.59555933e+00,\n",
       "        -7.61027348e+00,  -7.62498289e+00,  -7.63968750e+00,\n",
       "        -7.65438726e+00,  -7.66908212e+00,  -7.68377204e+00,\n",
       "        -7.69845696e+00,  -7.71313684e+00,  -7.72781162e+00,\n",
       "        -7.74248127e+00,  -7.75714573e+00,  -7.77180497e+00,\n",
       "        -7.78645893e+00,  -7.80110757e+00,  -7.81575085e+00,\n",
       "        -7.83038873e+00,  -7.84502116e+00,  -7.85964810e+00,\n",
       "        -7.87426952e+00,  -7.88888536e+00,  -7.90349560e+00,\n",
       "        -7.91810019e+00,  -7.93269909e+00,  -7.94729227e+00,\n",
       "        -7.96187969e+00,  -7.97646131e+00,  -7.99103710e+00,\n",
       "        -8.00560702e+00,  -8.02017104e+00,  -8.03472912e+00,\n",
       "        -8.04928123e+00,  -8.06382733e+00,  -8.07836740e+00,\n",
       "        -8.09290141e+00,  -8.10742931e+00,  -8.12195109e+00,\n",
       "        -8.13646671e+00,  -8.15097614e+00,  -8.16547935e+00,\n",
       "        -8.17997632e+00,  -8.19446702e+00,  -8.20895142e+00,\n",
       "        -8.22342949e+00,  -8.23790121e+00,  -8.25236656e+00,\n",
       "        -8.26682550e+00,  -8.28127802e+00,  -8.29572410e+00,\n",
       "        -8.31016370e+00,  -8.32459681e+00,  -8.33902340e+00,\n",
       "        -8.35344345e+00,  -8.36785695e+00,  -8.38226387e+00,\n",
       "        -8.39666419e+00,  -8.41105790e+00,  -8.42544497e+00,\n",
       "        -8.43982539e+00,  -8.45419913e+00,  -8.46856619e+00,\n",
       "        -8.48292655e+00,  -8.49728018e+00,  -8.51162708e+00,\n",
       "        -8.52596722e+00,  -8.54030060e+00,  -8.55462720e+00,\n",
       "        -8.56894701e+00,  -8.58326001e+00,  -8.59756619e+00,\n",
       "        -8.61186554e+00,  -8.62615805e+00,  -8.64044371e+00,\n",
       "        -8.65472249e+00,  -8.66899441e+00,  -8.68325944e+00,\n",
       "        -8.69751757e+00,  -8.71176880e+00,  -8.72601313e+00,\n",
       "        -8.74025053e+00,  -8.75448100e+00,  -8.76870454e+00,\n",
       "        -8.78292114e+00,  -8.79713079e+00,  -8.81133349e+00,\n",
       "        -8.82552923e+00,  -8.83971800e+00,  -8.85389981e+00,\n",
       "        -8.86807465e+00,  -8.88224250e+00,  -8.89640338e+00,\n",
       "        -8.91055728e+00,  -8.92470419e+00,  -8.93884411e+00,\n",
       "        -8.95297704e+00,  -8.96710299e+00,  -8.98122193e+00,\n",
       "        -8.99533389e+00,  -9.00943885e+00,  -9.02353682e+00,\n",
       "        -9.03762779e+00,  -9.05171178e+00,  -9.06578877e+00,\n",
       "        -9.07985876e+00,  -9.09392177e+00,  -9.10797780e+00,\n",
       "        -9.12202683e+00,  -9.13606889e+00,  -9.15010397e+00,\n",
       "        -9.16413207e+00,  -9.17815320e+00,  -9.19216736e+00,\n",
       "        -9.20617455e+00,  -9.22017479e+00,  -9.23416807e+00,\n",
       "        -9.24815440e+00,  -9.26213378e+00,  -9.27610623e+00,\n",
       "        -9.29007174e+00,  -9.30403033e+00,  -9.31798200e+00,\n",
       "        -9.33192675e+00,  -9.34586460e+00,  -9.35979555e+00,\n",
       "        -9.37371960e+00,  -9.38763678e+00,  -9.40154707e+00,\n",
       "        -9.41545050e+00,  -9.42934707e+00,  -9.44323679e+00,\n",
       "        -9.45711967e+00,  -9.47099571e+00,  -9.48486494e+00,\n",
       "        -9.49872735e+00,  -9.51258296e+00,  -9.52643177e+00,\n",
       "        -9.54027381e+00,  -9.55410907e+00,  -9.56793757e+00,\n",
       "        -9.58175932e+00,  -9.59557433e+00,  -9.60938261e+00,\n",
       "        -9.62318418e+00,  -9.63697905e+00,  -9.65076722e+00,\n",
       "        -9.66454871e+00,  -9.67832354e+00,  -9.69209171e+00,\n",
       "        -9.70585323e+00,  -9.71960813e+00,  -9.73335641e+00,\n",
       "        -9.74709809e+00,  -9.76083318e+00,  -9.77456169e+00,\n",
       "        -9.78828364e+00,  -9.80199904e+00,  -9.81570790e+00,\n",
       "        -9.82941025e+00,  -9.84310608e+00,  -9.85679543e+00,\n",
       "        -9.87047830e+00,  -9.88415470e+00,  -9.89782466e+00,\n",
       "        -9.91148818e+00,  -9.92514529e+00,  -9.93879599e+00,\n",
       "        -9.95244030e+00,  -9.96607825e+00,  -9.97970983e+00,\n",
       "        -9.99333508e+00,  -1.00069540e+01,  -1.00205666e+01,\n",
       "        -1.00341729e+01,  -1.00477730e+01,  -1.00613668e+01,\n",
       "        -1.00749543e+01,  -1.00885356e+01,  -1.01021107e+01,\n",
       "        -1.01156796e+01,  -1.01292423e+01,  -1.01427989e+01,\n",
       "        -1.01563493e+01,  -1.01698936e+01,  -1.01834318e+01,\n",
       "        -1.01969639e+01,  -1.02104899e+01,  -1.02240098e+01,\n",
       "        -1.02375237e+01,  -1.02510316e+01,  -1.02645335e+01,\n",
       "        -1.02780294e+01,  -1.02915193e+01,  -1.03050033e+01,\n",
       "        -1.03184813e+01,  -1.03319534e+01,  -1.03454196e+01,\n",
       "        -1.03588800e+01,  -1.03723344e+01,  -1.03857831e+01,\n",
       "        -1.03992258e+01,  -1.04126628e+01,  -1.04260940e+01,\n",
       "        -1.04395194e+01,  -1.04529391e+01,  -1.04663530e+01,\n",
       "        -1.04797612e+01,  -1.04931637e+01,  -1.05065605e+01,\n",
       "        -1.05199517e+01,  -1.05333372e+01,  -1.05467171e+01,\n",
       "        -1.05600913e+01,  -1.05734600e+01,  -1.05868231e+01,\n",
       "        -1.06001807e+01,  -1.06135327e+01,  -1.06268792e+01,\n",
       "        -1.06402202e+01,  -1.06535558e+01,  -1.06668858e+01,\n",
       "        -1.06802105e+01,  -1.06935297e+01,  -1.07068435e+01,\n",
       "        -1.07201519e+01,  -1.07334550e+01,  -1.07467527e+01,\n",
       "        -1.07600450e+01,  -1.07733321e+01,  -1.07866139e+01,\n",
       "        -1.07998904e+01,  -1.08131616e+01,  -1.08264277e+01,\n",
       "        -1.08396885e+01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted(X, AL)[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
